{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "#import cv\n",
    "import gc\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.engine import Layer\n",
    "\n",
    "from keras.layers import Input, Dense, Convolution3D, MaxPooling3D, Reshape, Flatten, BatchNormalization, Lambda, Dropout, Activation\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model, Sequential, model_from_json\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import vis.utils as utils\n",
    "#from vis.visualization import visualize_saliency\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sklearn.preprocessing as pre\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, random, gc, pickle\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import build_multiBranch as bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import datetime\\nprint(datetime.datetime.utcnow().strftime('%Y%m%d_%H-%M-%S'))\\n\\nimport torch\\n#print(torch._C._cudnn_version(), 'cudnn')\\n#print(torch._C._cuda_getDriverVersion(), 'cuda driver')\\nprint(torch._C._cuda_getCompiledVersion(), 'cuda compiled version')\\nprint(torch._C._nccl_version(), 'nccl')\\nfor i in range(torch.cuda.device_count()):\\n    print('device %s:'%i, torch.cuda.get_device_properties(i))\\n\\n    \\nimport subprocess\\nprint('\\nnvcc --version')\\nprint(subprocess.check_output('nvcc --version'.split(' ')).decode())\\nprint('\\nnvidia-smi')\\nprint(subprocess.check_output(['nvidia-smi']).decode())\\nprint('\\napt list nvidia-driver*')\\nprint(subprocess.check_output('apt list nvidia-driver*'.split(' ')).decode())\\nprint(subprocess.check_output('apt list *cudnn*'.split(' ')).decode())\\nprint(subprocess.check_output('apt list *cuda*'.split(' ')).decode())\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import datetime\n",
    "print(datetime.datetime.utcnow().strftime('%Y%m%d_%H-%M-%S'))\n",
    "\n",
    "import torch\n",
    "#print(torch._C._cudnn_version(), 'cudnn')\n",
    "#print(torch._C._cuda_getDriverVersion(), 'cuda driver')\n",
    "print(torch._C._cuda_getCompiledVersion(), 'cuda compiled version')\n",
    "print(torch._C._nccl_version(), 'nccl')\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print('device %s:'%i, torch.cuda.get_device_properties(i))\n",
    "\n",
    "    \n",
    "import subprocess\n",
    "print('\\nnvcc --version')\n",
    "print(subprocess.check_output('nvcc --version'.split(' ')).decode())\n",
    "print('\\nnvidia-smi')\n",
    "print(subprocess.check_output(['nvidia-smi']).decode())\n",
    "print('\\napt list nvidia-driver*')\n",
    "print(subprocess.check_output('apt list nvidia-driver*'.split(' ')).decode())\n",
    "print(subprocess.check_output('apt list *cudnn*'.split(' ')).decode())\n",
    "print(subprocess.check_output('apt list *cuda*'.split(' ')).decode())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CUDA_VISIBLE_DEVICES=3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''CUDA_VISIBLE_DEVICES=3'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import os\\nos.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"  # specify which GPU(s) to be used'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"  # specify which GPU(s) to be used'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import vis.utils as utils\n",
    "#from vis.visualization import visualize_saliency\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#import sklearn.preprocessing as pre\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "#from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "#import tensorflow as tf\n",
    "#import numpy as np\n",
    "#import nibabel as nib\n",
    "#import pandas as pd\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#import data_processing as process\n",
    "#import build_multiBranch as bm\n",
    "#import Fit_model as fitter\n",
    "#import Evaluate_model as Evalu\n",
    "#import generate_patches3D as generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from numba import jit, cuda'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from numba import jit, cuda'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import tensorflow as tf\\ntf.config.list_physical_devices('GPU')\\ntf.test.is_built_with_cuda()\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')\n",
    "tf.test.is_built_with_cuda()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from tensorflow.python.client import device_lib'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from tensorflow.python.client import device_lib'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'device_lib.list_local_devices'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''device_lib.list_local_devices'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('ADNI1_Screening_1.5T.csv')\n",
    "total_data = (metadata.Group !=0).values.astype('bool')\n",
    "\n",
    "dirName = '/home/dipnilc/Dipnil/ADNI_BET/ADNI1'\n",
    "\n",
    "#listOFFiles = process.getListOfFiles(dirName)\n",
    "#for elem in listOFFiles:\n",
    "    #print(elem)\n",
    "\n",
    "#print(\"***************\")\n",
    "\n",
    "listOfDirs = list()\n",
    "for (dirpath, dirnames, filenames) in os.walk(dirName):\n",
    "    listOfDirs += [os.path.join(dir) for dir in dirnames]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['123_S_0088',\n",
       " '027_S_0256',\n",
       " '073_S_0746',\n",
       " '016_S_0354',\n",
       " '137_S_0994',\n",
       " '041_S_0262',\n",
       " '067_S_1185',\n",
       " '005_S_1224',\n",
       " '023_S_0083',\n",
       " '002_S_0685',\n",
       " '022_S_1351',\n",
       " '073_S_0312',\n",
       " '018_S_0335',\n",
       " '109_S_1343',\n",
       " '098_S_0149',\n",
       " '036_S_0976',\n",
       " '073_S_0909',\n",
       " '020_S_1288',\n",
       " '128_S_1408',\n",
       " '041_S_1002',\n",
       " '141_S_0851',\n",
       " '052_S_1054',\n",
       " '068_S_0473',\n",
       " '014_S_0557',\n",
       " '010_S_0067',\n",
       " '023_S_0388',\n",
       " '005_S_0324',\n",
       " '016_S_0991',\n",
       " '012_S_1033',\n",
       " '023_S_0613',\n",
       " '137_S_0800',\n",
       " '141_S_1152',\n",
       " '128_S_0188',\n",
       " '007_S_0344',\n",
       " '141_S_0852',\n",
       " '109_S_1157',\n",
       " '006_S_0498',\n",
       " '128_S_0138',\n",
       " '016_S_1138',\n",
       " '127_S_0925',\n",
       " '033_S_0511',\n",
       " '002_S_1018',\n",
       " '133_S_1055',\n",
       " '098_S_0884',\n",
       " '130_S_0289',\n",
       " '130_S_1290',\n",
       " '013_S_0325',\n",
       " '128_S_1406',\n",
       " '041_S_1368',\n",
       " '013_S_0502',\n",
       " '022_S_0961',\n",
       " '114_S_0979',\n",
       " '136_S_0579',\n",
       " '137_S_1426',\n",
       " '051_S_1040',\n",
       " '114_S_1103',\n",
       " '027_S_0408',\n",
       " '130_S_1200',\n",
       " '941_S_1194',\n",
       " '057_S_1373',\n",
       " '116_S_0648',\n",
       " '067_S_1253',\n",
       " '018_S_0682',\n",
       " '011_S_0168',\n",
       " '099_S_0958',\n",
       " '127_S_0260',\n",
       " '016_S_0769',\n",
       " '033_S_0723',\n",
       " '041_S_1411',\n",
       " '128_S_0229',\n",
       " '128_S_0216',\n",
       " '137_S_0443',\n",
       " '126_S_1077',\n",
       " '109_S_1183',\n",
       " '068_S_0802',\n",
       " '114_S_0166',\n",
       " '128_S_0225',\n",
       " '029_S_0824',\n",
       " '133_S_0525',\n",
       " '033_S_1285',\n",
       " '098_S_0269',\n",
       " '014_S_0328',\n",
       " '041_S_1425',\n",
       " '024_S_1171',\n",
       " '009_S_0751',\n",
       " '021_S_0642',\n",
       " '057_S_1007',\n",
       " '128_S_1242',\n",
       " '130_S_0232',\n",
       " '041_S_1010',\n",
       " '123_S_0113',\n",
       " '022_S_0544',\n",
       " '057_S_0934',\n",
       " '032_S_0677',\n",
       " '127_S_0844',\n",
       " '035_S_0555',\n",
       " '098_S_0172',\n",
       " '033_S_0906',\n",
       " '021_S_0343',\n",
       " '002_S_0938',\n",
       " '032_S_0400',\n",
       " '137_S_0841',\n",
       " '127_S_0112',\n",
       " '023_S_1190',\n",
       " '099_S_0051',\n",
       " '031_S_0867',\n",
       " '002_S_0559',\n",
       " '131_S_1389',\n",
       " '100_S_0747',\n",
       " '131_S_0441',\n",
       " '036_S_1001',\n",
       " '003_S_0981',\n",
       " '036_S_0760',\n",
       " '023_S_1247',\n",
       " '130_S_0886',\n",
       " '003_S_1057',\n",
       " '031_S_0821',\n",
       " '016_S_1149',\n",
       " '023_S_0887',\n",
       " '067_S_0176',\n",
       " '051_S_1331',\n",
       " '127_S_0393',\n",
       " '024_S_1307',\n",
       " '029_S_1218',\n",
       " '100_S_0190',\n",
       " '013_S_0860',\n",
       " '062_S_0768',\n",
       " '109_S_1114',\n",
       " '002_S_0729',\n",
       " '116_S_1232',\n",
       " '022_S_0130',\n",
       " '137_S_0283',\n",
       " '003_S_1257',\n",
       " '136_S_0300',\n",
       " '136_S_0195',\n",
       " '003_S_0907',\n",
       " '094_S_0692',\n",
       " '041_S_1412',\n",
       " '082_S_0832',\n",
       " '129_S_0778',\n",
       " '027_S_0461',\n",
       " '129_S_1204',\n",
       " '128_S_1088',\n",
       " '023_S_1126',\n",
       " '131_S_0384',\n",
       " '031_S_1066',\n",
       " '021_S_0276',\n",
       " '033_S_0739',\n",
       " '123_S_0298',\n",
       " '073_S_0565',\n",
       " '023_S_0126',\n",
       " '003_S_1074',\n",
       " '024_S_0985',\n",
       " '033_S_0922',\n",
       " '141_S_1255',\n",
       " '053_S_0507',\n",
       " '021_S_0159',\n",
       " '128_S_0608',\n",
       " '041_S_0125',\n",
       " '136_S_0184',\n",
       " '073_S_0311',\n",
       " '016_S_1092',\n",
       " '036_S_0673',\n",
       " '109_S_1192',\n",
       " '136_S_0426',\n",
       " '014_S_1095',\n",
       " '036_S_0945',\n",
       " '128_S_0310',\n",
       " '116_S_0361',\n",
       " '018_S_0155',\n",
       " '035_S_0341',\n",
       " '062_S_1182',\n",
       " '014_S_0558',\n",
       " '021_S_0424',\n",
       " '099_S_0054',\n",
       " '011_S_0183',\n",
       " '012_S_1165',\n",
       " '114_S_0378',\n",
       " '033_S_0513',\n",
       " '062_S_0730',\n",
       " '052_S_1168',\n",
       " '031_S_0568',\n",
       " '941_S_1295',\n",
       " '114_S_0416',\n",
       " '009_S_1199',\n",
       " '082_S_0641',\n",
       " '131_S_0497',\n",
       " '035_S_0156',\n",
       " '094_S_1267',\n",
       " '023_S_0030',\n",
       " '128_S_0528',\n",
       " '123_S_0094',\n",
       " '013_S_0240',\n",
       " '094_S_0489',\n",
       " '022_S_0129',\n",
       " '128_S_0230',\n",
       " '127_S_1427',\n",
       " '130_S_0102',\n",
       " '141_S_1052',\n",
       " '022_S_0044',\n",
       " '133_S_0433',\n",
       " '082_S_0928',\n",
       " '100_S_1154',\n",
       " '133_S_1031',\n",
       " '033_S_0741',\n",
       " '068_S_0476',\n",
       " '941_S_1195',\n",
       " '109_S_1013',\n",
       " '128_S_0740',\n",
       " '016_S_1326',\n",
       " '002_S_1155',\n",
       " '123_S_0072',\n",
       " '127_S_1140',\n",
       " '094_S_1241',\n",
       " '130_S_0783',\n",
       " '100_S_0930',\n",
       " '137_S_0686',\n",
       " '033_S_0923',\n",
       " '128_S_0715',\n",
       " '027_S_1082',\n",
       " '037_S_0467',\n",
       " '100_S_1113',\n",
       " '021_S_0337',\n",
       " '133_S_0488',\n",
       " '011_S_0856',\n",
       " '011_S_0010',\n",
       " '009_S_1354',\n",
       " '014_S_0169',\n",
       " '131_S_0123',\n",
       " '021_S_1109',\n",
       " '114_S_1118',\n",
       " '072_S_1380',\n",
       " '011_S_0362',\n",
       " '131_S_0457',\n",
       " '067_S_0284',\n",
       " '014_S_0658',\n",
       " '016_S_0538',\n",
       " '099_S_1034',\n",
       " '023_S_0084',\n",
       " '033_S_0514',\n",
       " '021_S_0984',\n",
       " '068_S_0401',\n",
       " '067_S_0077',\n",
       " '057_S_1379',\n",
       " '011_S_0022',\n",
       " '114_S_0173',\n",
       " '018_S_0450',\n",
       " '094_S_0526',\n",
       " '082_S_0304',\n",
       " '057_S_0839',\n",
       " '023_S_1289',\n",
       " '128_S_0611',\n",
       " '130_S_0423',\n",
       " '021_S_0626',\n",
       " '009_S_0842',\n",
       " '094_S_1102',\n",
       " '013_S_1205',\n",
       " '062_S_1294',\n",
       " '023_S_0604',\n",
       " '021_S_0178',\n",
       " '052_S_0951',\n",
       " '141_S_1231',\n",
       " '094_S_0434',\n",
       " '128_S_1043',\n",
       " '128_S_0200',\n",
       " '014_S_0563',\n",
       " '012_S_0712',\n",
       " '023_S_0331',\n",
       " '941_S_1363',\n",
       " '057_S_0643',\n",
       " '126_S_0405',\n",
       " '027_S_0835',\n",
       " '010_S_0420',\n",
       " '006_S_0484',\n",
       " '002_S_0954',\n",
       " '094_S_1402',\n",
       " '123_S_0091',\n",
       " '082_S_0363',\n",
       " '013_S_0592',\n",
       " '136_S_0299',\n",
       " '035_S_0292',\n",
       " '129_S_1246',\n",
       " '007_S_0316',\n",
       " '141_S_1244',\n",
       " '094_S_1188',\n",
       " '116_S_0370',\n",
       " '013_S_1120',\n",
       " '029_S_1318',\n",
       " '114_S_0374',\n",
       " '128_S_0517',\n",
       " '067_S_0828',\n",
       " '141_S_1245',\n",
       " '003_S_1021',\n",
       " '052_S_0952',\n",
       " '136_S_0695',\n",
       " '116_S_1249',\n",
       " '099_S_0492',\n",
       " '116_S_0382',\n",
       " '126_S_0708',\n",
       " '007_S_0128',\n",
       " '116_S_1243',\n",
       " '057_S_0941',\n",
       " '033_S_1098',\n",
       " '032_S_0718',\n",
       " '941_S_1311',\n",
       " '031_S_0554',\n",
       " '137_S_1414',\n",
       " '094_S_0921',\n",
       " '021_S_0332',\n",
       " '027_S_1385',\n",
       " '141_S_0697',\n",
       " '123_S_0050',\n",
       " '137_S_0631',\n",
       " '041_S_1391',\n",
       " '094_S_1090',\n",
       " '033_S_0567',\n",
       " '012_S_0803',\n",
       " '130_S_0505',\n",
       " '018_S_0057',\n",
       " '051_S_1131',\n",
       " '037_S_1078',\n",
       " '127_S_1382',\n",
       " '032_S_1169',\n",
       " '067_S_0076',\n",
       " '033_S_1308',\n",
       " '033_S_0889',\n",
       " '094_S_1314',\n",
       " '128_S_0522',\n",
       " '023_S_1046',\n",
       " '018_S_0087',\n",
       " '005_S_0221',\n",
       " '010_S_0422',\n",
       " '005_S_0572',\n",
       " '011_S_0016',\n",
       " '114_S_1106',\n",
       " '100_S_1286',\n",
       " '100_S_0892',\n",
       " '128_S_0770',\n",
       " '005_S_0546',\n",
       " '121_S_1350',\n",
       " '137_S_0366',\n",
       " '068_S_0442',\n",
       " '021_S_0231',\n",
       " '029_S_1073',\n",
       " '029_S_0845',\n",
       " '137_S_0158',\n",
       " '094_S_0711',\n",
       " '041_S_0721',\n",
       " '018_S_0633',\n",
       " '100_S_0035',\n",
       " '037_S_0182',\n",
       " '062_S_1299',\n",
       " '014_S_0520',\n",
       " '033_S_0733',\n",
       " '010_S_0472',\n",
       " '128_S_0863',\n",
       " '067_S_0257',\n",
       " '027_S_1277',\n",
       " '037_S_0627',\n",
       " '023_S_0625',\n",
       " '099_S_0533',\n",
       " '020_S_0097',\n",
       " '003_S_0908',\n",
       " '141_S_0810',\n",
       " '012_S_0932',\n",
       " '027_S_0850',\n",
       " '128_S_0258',\n",
       " '007_S_0249',\n",
       " '005_S_0929',\n",
       " '141_S_0915',\n",
       " '041_S_0407',\n",
       " '099_S_0111',\n",
       " '127_S_1210',\n",
       " '037_S_1225',\n",
       " '007_S_0068',\n",
       " '057_S_1269',\n",
       " '041_S_0598',\n",
       " '126_S_0506',\n",
       " '141_S_1024',\n",
       " '020_S_0899',\n",
       " '012_S_1292',\n",
       " '011_S_0023',\n",
       " '116_S_0392',\n",
       " '024_S_1393',\n",
       " '023_S_0081',\n",
       " '027_S_0644',\n",
       " '137_S_0438',\n",
       " '037_S_0327',\n",
       " '099_S_0090',\n",
       " '005_S_1341',\n",
       " '010_S_0829',\n",
       " '035_S_0997',\n",
       " '036_S_1135',\n",
       " '137_S_0301',\n",
       " '133_S_1170',\n",
       " '116_S_1083',\n",
       " '100_S_1062',\n",
       " '099_S_0291',\n",
       " '100_S_0006',\n",
       " '003_S_1059',\n",
       " '021_S_0647',\n",
       " '053_S_0919',\n",
       " '021_S_0141',\n",
       " '002_S_1070',\n",
       " '116_S_0834',\n",
       " '029_S_1184',\n",
       " '067_S_0019',\n",
       " '131_S_0319',\n",
       " '027_S_0074',\n",
       " '035_S_0048',\n",
       " '027_S_1387',\n",
       " '006_S_0547',\n",
       " '136_S_0086',\n",
       " '006_S_0675',\n",
       " '020_S_0883',\n",
       " '123_S_0162',\n",
       " '027_S_1213',\n",
       " '002_S_1268',\n",
       " '023_S_0855',\n",
       " '136_S_0186',\n",
       " '128_S_0947',\n",
       " '007_S_0070',\n",
       " '051_S_1296',\n",
       " '121_S_1322',\n",
       " '011_S_0003',\n",
       " '016_S_0702',\n",
       " '036_S_1023',\n",
       " '053_S_1044',\n",
       " '023_S_0963',\n",
       " '067_S_0607',\n",
       " '032_S_0187',\n",
       " '067_S_0038',\n",
       " '029_S_0843',\n",
       " '057_S_0474',\n",
       " '137_S_0481',\n",
       " '099_S_0352',\n",
       " '029_S_1038',\n",
       " '033_S_1086',\n",
       " '123_S_0390',\n",
       " '133_S_0771',\n",
       " '137_S_0825',\n",
       " '002_S_1280',\n",
       " '010_S_0161',\n",
       " '012_S_0637',\n",
       " '011_S_0008',\n",
       " '082_S_1119',\n",
       " '094_S_0531',\n",
       " '082_S_0469',\n",
       " '009_S_1030',\n",
       " '062_S_0690',\n",
       " '094_S_1015',\n",
       " '099_S_0880',\n",
       " '031_S_0321',\n",
       " '126_S_0606',\n",
       " '032_S_1037',\n",
       " '037_S_0539',\n",
       " '041_S_0282',\n",
       " '018_S_0286',\n",
       " '022_S_0096',\n",
       " '027_S_0403',\n",
       " '009_S_0862',\n",
       " '033_S_0724',\n",
       " '068_S_0872',\n",
       " '136_S_0107',\n",
       " '130_S_1201',\n",
       " '126_S_0680',\n",
       " '098_S_0896',\n",
       " '002_S_0619',\n",
       " '131_S_0436',\n",
       " '022_S_0066',\n",
       " '016_S_1117',\n",
       " '133_S_0912',\n",
       " '137_S_0668',\n",
       " '033_S_1281',\n",
       " '018_S_0080',\n",
       " '041_S_1260',\n",
       " '032_S_0479',\n",
       " '116_S_0487',\n",
       " '011_S_0861',\n",
       " '127_S_0397',\n",
       " '126_S_1187',\n",
       " '131_S_1301',\n",
       " '130_S_0449',\n",
       " '007_S_1304',\n",
       " '002_S_1261',\n",
       " '031_S_0351',\n",
       " '067_S_0056',\n",
       " '036_S_1240',\n",
       " '068_S_0109',\n",
       " '033_S_1279',\n",
       " '027_S_0116',\n",
       " '011_S_0021',\n",
       " '098_S_0171',\n",
       " '130_S_0956',\n",
       " '023_S_1306',\n",
       " '012_S_1321',\n",
       " '011_S_1080',\n",
       " '023_S_1262',\n",
       " '137_S_0669',\n",
       " '126_S_0891',\n",
       " '032_S_0978',\n",
       " '029_S_0878',\n",
       " '128_S_0545',\n",
       " '033_S_1016',\n",
       " '109_S_1014',\n",
       " '022_S_0750',\n",
       " '068_S_0478',\n",
       " '128_S_0205',\n",
       " '032_S_1101',\n",
       " '136_S_0874',\n",
       " '132_S_0339',\n",
       " '941_S_1197',\n",
       " '109_S_0950',\n",
       " '012_S_0689',\n",
       " '005_S_0610',\n",
       " '013_S_0699',\n",
       " '099_S_0372',\n",
       " '051_S_1123',\n",
       " '014_S_0519',\n",
       " '126_S_0605',\n",
       " '094_S_1398',\n",
       " '067_S_0029',\n",
       " '128_S_1148',\n",
       " '067_S_0243',\n",
       " '094_S_1417',\n",
       " '041_S_1418',\n",
       " '016_S_0359',\n",
       " '007_S_0293',\n",
       " '141_S_1094',\n",
       " '116_S_0890',\n",
       " '082_S_0761',\n",
       " '126_S_1340',\n",
       " '114_S_0228',\n",
       " '094_S_1293',\n",
       " '057_S_0464',\n",
       " '098_S_0288',\n",
       " '012_S_1212',\n",
       " '116_S_0657',\n",
       " '023_S_0058',\n",
       " '062_S_0578',\n",
       " '141_S_0853',\n",
       " '022_S_0014',\n",
       " '094_S_1027',\n",
       " '052_S_1250',\n",
       " '126_S_1221',\n",
       " '023_S_0139',\n",
       " '013_S_1161',\n",
       " '033_S_1309',\n",
       " '033_S_1284',\n",
       " '068_S_1191',\n",
       " '099_S_1144',\n",
       " '062_S_1099',\n",
       " '012_S_0720',\n",
       " '067_S_0059',\n",
       " '072_S_0315',\n",
       " '018_S_0103',\n",
       " '136_S_0194',\n",
       " '127_S_0259',\n",
       " '033_S_0516',\n",
       " '031_S_0618',\n",
       " '035_S_0033',\n",
       " '011_S_0053',\n",
       " '024_S_1063',\n",
       " '133_S_0493',\n",
       " '005_S_0223',\n",
       " '018_S_0142',\n",
       " '007_S_0101',\n",
       " '012_S_0634',\n",
       " '018_S_0369',\n",
       " '100_S_0015',\n",
       " '100_S_0047',\n",
       " '002_S_0816',\n",
       " '022_S_0543',\n",
       " '023_S_0093',\n",
       " '067_S_0110',\n",
       " '141_S_1004',\n",
       " '094_S_1330',\n",
       " '053_S_0389',\n",
       " '013_S_1035',\n",
       " '100_S_0296',\n",
       " '126_S_0784',\n",
       " '116_S_0360',\n",
       " '037_S_0454',\n",
       " '114_S_0458',\n",
       " '036_S_0748',\n",
       " '012_S_1009',\n",
       " '033_S_0725',\n",
       " '011_S_1282',\n",
       " '011_S_0002',\n",
       " '068_S_1075',\n",
       " '057_S_1371',\n",
       " '003_S_0931',\n",
       " '072_S_1211',\n",
       " '099_S_0470',\n",
       " '130_S_1337',\n",
       " '022_S_0004',\n",
       " '099_S_0534',\n",
       " '010_S_0786',\n",
       " '007_S_0041',\n",
       " '068_S_0127',\n",
       " '082_S_1377',\n",
       " '006_S_0653',\n",
       " '130_S_0285',\n",
       " '123_S_0108',\n",
       " '037_S_1421',\n",
       " '002_S_0295',\n",
       " '100_S_0069',\n",
       " '010_S_0419',\n",
       " '131_S_0691',\n",
       " '007_S_0414',\n",
       " '067_S_0336',\n",
       " '032_S_0214',\n",
       " '037_S_0303',\n",
       " '022_S_0007',\n",
       " '020_S_0213',\n",
       " '027_S_0404',\n",
       " '011_S_0241',\n",
       " '023_S_0916',\n",
       " '027_S_0179',\n",
       " '032_S_0095',\n",
       " '128_S_0500',\n",
       " '003_S_1122',\n",
       " '141_S_0696',\n",
       " '141_S_0726',\n",
       " '131_S_0409',\n",
       " '016_S_0590',\n",
       " '023_S_0078',\n",
       " '037_S_0566',\n",
       " '141_S_0717',\n",
       " '023_S_1104',\n",
       " '067_S_0290',\n",
       " '036_S_0869',\n",
       " '022_S_1097',\n",
       " '127_S_0622',\n",
       " '109_S_0876',\n",
       " '137_S_0973',\n",
       " '011_S_0326',\n",
       " '002_S_0782',\n",
       " '022_S_1394',\n",
       " '036_S_0577',\n",
       " '041_S_0446',\n",
       " '005_S_0222',\n",
       " '031_S_1209',\n",
       " '018_S_0425',\n",
       " '016_S_1028',\n",
       " '052_S_1251',\n",
       " '132_S_0987',\n",
       " '031_S_0294',\n",
       " '128_S_0167',\n",
       " '051_S_1338',\n",
       " '098_S_0160',\n",
       " '941_S_1203',\n",
       " '031_S_0830',\n",
       " '037_S_0552',\n",
       " '116_S_0649',\n",
       " '023_S_0042',\n",
       " '127_S_1419',\n",
       " '052_S_0989',\n",
       " '012_S_0917',\n",
       " '141_S_0982',\n",
       " '067_S_0098',\n",
       " '128_S_1407',\n",
       " '128_S_0266',\n",
       " '127_S_0431',\n",
       " '033_S_1116',\n",
       " '141_S_1378',\n",
       " '041_S_1423',\n",
       " '062_S_0535',\n",
       " '116_S_1315',\n",
       " '109_S_0777',\n",
       " '094_S_1164',\n",
       " '013_S_0575',\n",
       " '016_S_1263',\n",
       " '116_S_0752',\n",
       " '041_S_0898',\n",
       " '036_S_0656',\n",
       " '007_S_1248',\n",
       " '073_S_1357',\n",
       " '100_S_0995',\n",
       " '013_S_1276',\n",
       " '029_S_0836',\n",
       " '126_S_0709',\n",
       " '029_S_0999',\n",
       " '041_S_0314',\n",
       " '068_S_0210',\n",
       " '082_S_1256',\n",
       " '033_S_0734',\n",
       " '011_S_0005',\n",
       " '098_S_0667',\n",
       " '023_S_0376',\n",
       " '109_S_0967',\n",
       " '033_S_1283',\n",
       " '057_S_0779',\n",
       " '005_S_0448',\n",
       " '073_S_0089',\n",
       " '022_S_1366',\n",
       " '099_S_0040',\n",
       " '014_S_0356',\n",
       " '073_S_0386',\n",
       " '021_S_0753',\n",
       " '073_S_0445',\n",
       " '123_S_0106',\n",
       " '041_S_1435',\n",
       " '114_S_0410',\n",
       " '127_S_0394',\n",
       " '036_S_0576',\n",
       " '027_S_0120',\n",
       " '013_S_0996',\n",
       " '053_S_0621',\n",
       " '114_S_0601',\n",
       " '057_S_0818',\n",
       " '116_S_1271',\n",
       " '141_S_0767',\n",
       " '127_S_0754',\n",
       " '036_S_0759',\n",
       " '023_S_0031',\n",
       " '009_S_1334',\n",
       " '133_S_0727',\n",
       " '032_S_0147',\n",
       " '027_S_1045',\n",
       " '027_S_0417',\n",
       " '128_S_1409',\n",
       " '062_S_0793',\n",
       " '013_S_1275',\n",
       " '023_S_0926',\n",
       " '128_S_0272',\n",
       " '005_S_0553',\n",
       " '126_S_0865',\n",
       " '128_S_0227',\n",
       " '005_S_0602',\n",
       " '133_S_0629',\n",
       " '941_S_1202',\n",
       " '141_S_0790',\n",
       " '123_S_1300',\n",
       " '133_S_0792',\n",
       " '023_S_0217',\n",
       " '022_S_0219',\n",
       " '052_S_1352',\n",
       " '141_S_1137',\n",
       " '057_S_1265',\n",
       " '041_S_1420',\n",
       " '029_S_0866',\n",
       " '002_S_0413',\n",
       " '018_S_0043',\n",
       " '067_S_0045',\n",
       " '007_S_1339',\n",
       " '127_S_1032',\n",
       " '024_S_1400',\n",
       " '022_S_0924',\n",
       " '036_S_0672',\n",
       " '136_S_0873',\n",
       " '128_S_1430',\n",
       " '136_S_0196',\n",
       " '037_S_0501',\n",
       " '037_S_0150',\n",
       " '082_S_1079',\n",
       " '029_S_0871',\n",
       " '037_S_0588',\n",
       " '023_S_0061',\n",
       " '007_S_0698',\n",
       " '036_S_0813',\n",
       " '037_S_0377',\n",
       " '035_S_0204',\n",
       " '006_S_0731',\n",
       " '007_S_1222',\n",
       " '013_S_1186',\n",
       " '128_S_0135',\n",
       " '133_S_0913',\n",
       " '073_S_0518',\n",
       " '012_S_1133',\n",
       " '014_S_0548',\n",
       " '007_S_1206',\n",
       " '137_S_0972',\n",
       " '137_S_0459',\n",
       " '012_S_1175',\n",
       " '041_S_0679',\n",
       " '027_S_1254',\n",
       " '067_S_0812',\n",
       " '005_S_0814',\n",
       " '128_S_0245',\n",
       " '141_S_1051',\n",
       " '010_S_0904',\n",
       " '094_S_1397',\n",
       " '137_S_0796',\n",
       " '029_S_1215',\n",
       " '029_S_1056',\n",
       " '057_S_1217',\n",
       " '029_S_1384',\n",
       " '100_S_0743',\n",
       " '033_S_0920',\n",
       " '041_S_0549',\n",
       " '052_S_1346',\n",
       " '099_S_0060',\n",
       " '016_S_1121',\n",
       " '099_S_0551',\n",
       " '002_S_0955',\n",
       " '018_S_0406',\n",
       " '027_S_0118',\n",
       " '027_S_0307',\n",
       " '051_S_1072',\n",
       " '057_S_0957',\n",
       " '027_S_0485',\n",
       " '082_S_0640',\n",
       " '137_S_0722',\n",
       " '067_S_0177',\n",
       " '029_S_0914',\n",
       " '021_S_0273',\n",
       " '133_S_0638',\n",
       " '006_S_1130',\n",
       " '006_S_0681',\n",
       " '127_S_0684',\n",
       " '027_S_1081',\n",
       " '052_S_0671',\n",
       " '137_S_1041',\n",
       " '130_S_0969',\n",
       " '136_S_0429',\n",
       " '136_S_1227']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOfDirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfFiles = list()\n",
    "for (dirpath, dirnames, filenames) in os.walk(dirName):\n",
    "    listOfFiles += [os.path.join(dirpath,dir,dir)+'_pve_0.nii.gz' for dir in dirnames]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#listOfFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure each subject appear at most once in the training data and so does in the test data.\n",
    "subjects_count = 0\n",
    "subjects_dict = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(817,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure each subject appear at most once in the training data and so does in the test data.\n",
    "subjects_count = 0\n",
    "subjects_dict = []\n",
    "for elem in listOfFiles:\n",
    "    #im = 'ADNI_002_S_0413_MR_MPR____N3__Scaled_Br_20070216232854688_S14782_I40657.nii'\n",
    "    #img = nib.load(elem).get_data()\n",
    "    #img = np.asarray(img)\n",
    "    split_names = elem.split('/')\n",
    "    subject_name = split_names[6]\n",
    "    if subjects_count==0:\n",
    "        subjects_count +=1\n",
    "        subjects_dict.append(subject_name)\n",
    "    else:\n",
    "        if subject_name in subjects_dict:\n",
    "            subjects_count += 0\n",
    "            #subjects_dict.append(subject_name)\n",
    "\t    #continue\n",
    "        else:\n",
    "            subjects_count += 1\n",
    "            subjects_dict.append(subject_name)\n",
    "    if subjects_count>1072:\n",
    "         break\n",
    "np.shape(subjects_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_dict1=subjects_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(817,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(subjects_dict1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros((int(subjects_count), 155, 155, 95))\n",
    "labels = np.zeros((int(subjects_count), 1))\n",
    "labels_C = np.zeros((int(subjects_count), 1))\n",
    "#scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>1068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>1069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>1071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>1072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1073 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Index\n",
       "0         0\n",
       "1         1\n",
       "2         2\n",
       "3         3\n",
       "4         4\n",
       "...     ...\n",
       "1068   1068\n",
       "1069   1069\n",
       "1070   1070\n",
       "1071   1071\n",
       "1072   1072\n",
       "\n",
       "[1073 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx=pd.DataFrame(np.arange(0,1073))\n",
    "idx.columns=['Index']\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Image Data ID</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Group</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Visit</th>\n",
       "      <th>Modality</th>\n",
       "      <th>Description</th>\n",
       "      <th>Type</th>\n",
       "      <th>Acq Date</th>\n",
       "      <th>Format</th>\n",
       "      <th>Downloaded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>63897</td>\n",
       "      <td>941_S_1363</td>\n",
       "      <td>MCI</td>\n",
       "      <td>F</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>3/12/2007</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/18/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>97327</td>\n",
       "      <td>941_S_1311</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>3/02/2007</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/18/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>63888</td>\n",
       "      <td>941_S_1295</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>2/09/2007</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/18/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>63879</td>\n",
       "      <td>941_S_1203</td>\n",
       "      <td>CN</td>\n",
       "      <td>M</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>1/29/2007</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/18/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>63874</td>\n",
       "      <td>941_S_1202</td>\n",
       "      <td>CN</td>\n",
       "      <td>M</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR-R; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>1/30/2007</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/18/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>1068</td>\n",
       "      <td>40674</td>\n",
       "      <td>002_S_0559</td>\n",
       "      <td>CN</td>\n",
       "      <td>M</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>5/23/2006</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/18/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>1069</td>\n",
       "      <td>45117</td>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>CN</td>\n",
       "      <td>F</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>5/02/2006</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/18/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>1070</td>\n",
       "      <td>118673</td>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>CN</td>\n",
       "      <td>F</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled_2</td>\n",
       "      <td>Processed</td>\n",
       "      <td>5/02/2006</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/18/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>1071</td>\n",
       "      <td>45108</td>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>CN</td>\n",
       "      <td>M</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>4/18/2006</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/18/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>1072</td>\n",
       "      <td>118671</td>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>CN</td>\n",
       "      <td>M</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled_2</td>\n",
       "      <td>Processed</td>\n",
       "      <td>4/18/2006</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/18/2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1073 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Index  Image Data ID     Subject Group Sex  Age  Visit Modality  \\\n",
       "0         0          63897  941_S_1363   MCI   F   70      1      MRI   \n",
       "1         1          97327  941_S_1311   MCI   M   69      1      MRI   \n",
       "2         2          63888  941_S_1295   MCI   M   77      1      MRI   \n",
       "3         3          63879  941_S_1203    CN   M   83      1      MRI   \n",
       "4         4          63874  941_S_1202    CN   M   78      1      MRI   \n",
       "...     ...            ...         ...   ...  ..  ...    ...      ...   \n",
       "1068   1068          40674  002_S_0559    CN   M   79      1      MRI   \n",
       "1069   1069          45117  002_S_0413    CN   F   76      1      MRI   \n",
       "1070   1070         118673  002_S_0413    CN   F   76      1      MRI   \n",
       "1071   1071          45108  002_S_0295    CN   M   85      1      MRI   \n",
       "1072   1072         118671  002_S_0295    CN   M   85      1      MRI   \n",
       "\n",
       "                                     Description       Type   Acq Date Format  \\\n",
       "0       MPR; GradWarp; B1 Correction; N3; Scaled  Processed  3/12/2007  NiFTI   \n",
       "1       MPR; GradWarp; B1 Correction; N3; Scaled  Processed  3/02/2007  NiFTI   \n",
       "2       MPR; GradWarp; B1 Correction; N3; Scaled  Processed  2/09/2007  NiFTI   \n",
       "3       MPR; GradWarp; B1 Correction; N3; Scaled  Processed  1/29/2007  NiFTI   \n",
       "4     MPR-R; GradWarp; B1 Correction; N3; Scaled  Processed  1/30/2007  NiFTI   \n",
       "...                                          ...        ...        ...    ...   \n",
       "1068    MPR; GradWarp; B1 Correction; N3; Scaled  Processed  5/23/2006  NiFTI   \n",
       "1069    MPR; GradWarp; B1 Correction; N3; Scaled  Processed  5/02/2006  NiFTI   \n",
       "1070  MPR; GradWarp; B1 Correction; N3; Scaled_2  Processed  5/02/2006  NiFTI   \n",
       "1071    MPR; GradWarp; B1 Correction; N3; Scaled  Processed  4/18/2006  NiFTI   \n",
       "1072  MPR; GradWarp; B1 Correction; N3; Scaled_2  Processed  4/18/2006  NiFTI   \n",
       "\n",
       "     Downloaded  \n",
       "0     1/18/2019  \n",
       "1     1/18/2019  \n",
       "2     1/18/2019  \n",
       "3     1/18/2019  \n",
       "4     1/18/2019  \n",
       "...         ...  \n",
       "1068  1/18/2019  \n",
       "1069  1/18/2019  \n",
       "1070  1/18/2019  \n",
       "1071  1/18/2019  \n",
       "1072  1/18/2019  \n",
       "\n",
       "[1073 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata1=pd.concat([idx,metadata],axis=1)\n",
    "metadata1[total_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 166)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = nib.load(elem).get_fdata()\n",
    "img = np.asarray(img)\n",
    "np.shape(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_img = 0\n",
    "for elem in listOfFiles:\n",
    "    split_names = elem.split('/')\n",
    "    subject_name = split_names[6]\n",
    "    if subject_name in subjects_dict:\n",
    "        img = nib.load(elem).get_fdata()\n",
    "        img = np.asarray(img)\n",
    "        img = img[35:190, 35:190, 40:135]\n",
    "        scaler1 = MinMaxScaler()\n",
    "        for jj in range(95):\n",
    "            img[:, :, jj] = scaler1.fit_transform(img[:, :, jj])\n",
    "        scaler2 = MinMaxScaler()\n",
    "        for tt in range(155):\n",
    "            img[tt, :, :] = scaler2.fit_transform(img[tt, :, :])\n",
    "        scaler3 = MinMaxScaler()\n",
    "        for kk in range(155):\n",
    "            img[:, kk, :] = scaler3.fit_transform(img[:, kk, :])\n",
    "\n",
    "        data[ind_img, :, :, :] = img\n",
    "        indexM=metadata1.loc[metadata1['Subject']==(subject_name)]\n",
    "    #indexM = int(indexM[0])\n",
    "        group=metadata1.Group[metadata1['Subject']==(subject_name)] \n",
    "        #print(group[0])\n",
    "        group=pd.DataFrame(group)       \n",
    "        group = group.iloc[0]['Group']\n",
    "        if group=='AD':\n",
    "            label = 2\n",
    "            label_c = 0\n",
    "        if group=='CN':\n",
    "            label = 0\n",
    "            label_c = 1\n",
    "        if group=='MCI':\n",
    "            label = 1\n",
    "            label_c = 0\n",
    "        labels[ind_img] = label\n",
    "        labels_C[ind_img] = label_c\n",
    "        ind_img += 1\n",
    "        sub_ind = subjects_dict.index(subject_name)\n",
    "        subjects_dict.pop(sub_ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(817,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOfFiles = list()\n",
    "for (dirpath, dirnames, filenames) in os.walk(dirName):\n",
    "    listOfFiles += [os.path.join(dirpath,dir,dir)+'_pve_0.nii.gz' for dir in dirnames]\n",
    "# make sure each subject appear at most once in the training data and so does in the test data.\n",
    "subjects_count = 0\n",
    "subjects_dict = []\n",
    "for elem in listOfFiles:\n",
    "    #im = 'ADNI_002_S_0413_MR_MPR____N3__Scaled_Br_20070216232854688_S14782_I40657.nii'\n",
    "    #img = nib.load(elem).get_data()\n",
    "    #img = np.asarray(img)\n",
    "    split_names = elem.split('/')\n",
    "    subject_name = split_names[6]\n",
    "    if subjects_count==0:\n",
    "        subjects_count +=1\n",
    "        subjects_dict.append(subject_name)\n",
    "    else:\n",
    "        if subject_name in subjects_dict:\n",
    "            subjects_count += 0\n",
    "            #subjects_dict.append(subject_name)\n",
    "\t    #continue\n",
    "        else:\n",
    "            subjects_count += 1\n",
    "            subjects_dict.append(subject_name)\n",
    "    if subjects_count>1072:\n",
    "         break\n",
    "np.shape(subjects_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(817, 155, 155, 95, 1)\n"
     ]
    }
   ],
   "source": [
    "#data = scaler.fit(data)\n",
    "data = np.reshape(data, (data.shape[0], data.shape[1], data.shape[2], data.shape[3], 1))\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the data\n"
     ]
    }
   ],
   "source": [
    "X_train1, X_test, Y_train1, Y_test, id_train1,id_test = train_test_split(data, labels,subjects_dict, test_size=0.1, train_size=0.9, random_state=7)\n",
    "\n",
    "#X_train, X_test, Y_train_C, Y_test_C = train_test_split(data, labels_C, test_size=0.1, train_size=0.9, random_state=7)\n",
    "#np.save(\"Labels2_tr\", Y_train)\n",
    "#np.save(\"Labels2_ts\", Y_test)\n",
    "#np.save(\"Labels2_C_tr\", Y_train_C)\n",
    "#np.save(\"Labels2_C_ts\", Y_test_C)\n",
    "#Y_train = np_utils.to_categorical(Y_train, 3)\n",
    "Y_test = np_utils.to_categorical(Y_test, 3)\n",
    "#Y_train_C = np_utils.to_categorical(Y_train_C, 2)\n",
    "#Y_test_C = np_utils.to_categorical(Y_test_C, 2)\n",
    "#np.save(\"wholeImg_tr\", X_train)\n",
    "#np.save(\"wholeImg_ts\", X_test)\n",
    "#num_tr = X_train.shape[0]\n",
    "#num_ts = X_test.shape[0]\n",
    "print(\"Saved the data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, Y_train, Y_validation, id_train,id_validation = train_test_split(X_train1, Y_train1,id_train1, test_size=1/9, train_size=8/9, random_state=7)\n",
    "Y_train = np_utils.to_categorical(Y_train, 3)\n",
    "Y_validation = np_utils.to_categorical(Y_validation, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(653, 155, 155, 95, 1)\n",
      "(82, 155, 155, 95, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_branches = 27\n",
    "batch_size = 4\n",
    "nb_epochs = 10\n",
    "early_stopping_patience = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 155\n",
    "img_size_x = 155\n",
    "img_size_y = 95\n",
    "batch_size = 4\n",
    "nb_classes = 3\n",
    "nb_epochs = 25\n",
    "learning_rate = 0.003\n",
    "early_stopping_patience = 10\n",
    "class_names = [\"AD\",\"CN\", \"MCI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids=pd.concat([pd.DataFrame(id_train),pd.DataFrame(id_validation),pd.DataFrame(id_test)],axis=0)\n",
    "pd.DataFrame(ids).to_csv(\"/home/dipnilc/Dipnil/Codes/features_ID_GM_917_TrVaTs.csv\", header=None, sep=',',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"3D-CNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 155, 155, 95, 1)] 0         \n",
      "_________________________________________________________________\n",
      "conv3d_108 (Conv3D)          (None, 153, 153, 93, 64)  1792      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_54 (MaxPooling (None, 76, 76, 46, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_108 (Bat (None, 76, 76, 46, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv3d_109 (Conv3D)          (None, 74, 74, 44, 64)    110656    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_55 (MaxPooling (None, 37, 37, 22, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_109 (Bat (None, 37, 37, 22, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv3d_110 (Conv3D)          (None, 35, 35, 20, 128)   221312    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_56 (MaxPooling (None, 17, 17, 10, 128)   0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_110 (Bat (None, 17, 17, 10, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv3d_111 (Conv3D)          (None, 15, 15, 8, 256)    884992    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_57 (MaxPooling (None, 7, 7, 4, 256)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_111 (Bat (None, 7, 7, 4, 256)      1024      \n",
      "_________________________________________________________________\n",
      "global_average_pooling3d (Gl (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               51300     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 1,403,987\n",
      "Trainable params: 1,402,963\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "def get_model(width=155, height=155, depth=95):\n",
    "    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n",
    "\n",
    "    inputs = keras.Input((155, 155, 95, 1))\n",
    "\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    x = layers.Dense(units=512, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(units=100, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    outputs = layers.Dense(units=nb_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    # Define the model.\n",
    "    model = keras.Model(inputs, outputs, name=\"3D-CNN\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Build model.\n",
    "model = get_model(width=155, height=155, depth=95)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model.\n",
    "initial_learning_rate = 0.0001\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    metrics=[\"acc\",tf.keras.metrics.AUC()],\n",
    ")\n",
    "inputs = keras.Input((155, 155, 95, 1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks.\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    \"3d_image_GM_classification.h5\", save_best_only=True\n",
    ")\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_acc\", patience=15)\n",
    "\n",
    "# Train the model, doing validation at the end of each epoch\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 849s 5s/step - loss: 0.6240 - acc: 0.4334 - auc_1: 0.6066 - val_loss: 0.8323 - val_acc: 0.5488 - val_auc_1: 0.6865\n"
     ]
    }
   ],
   "source": [
    "m = model.fit(X_train, Y_train,batch_size=4,epochs=1,verbose=1, shuffle=True, validation_data=(X_validation, Y_validation),callbacks=[checkpoint_cb, early_stopping_cb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10797741, 0.6272079 , 0.2648147 ],\n",
       "       [0.10276509, 0.6203982 , 0.2768367 ],\n",
       "       [0.1042094 , 0.62251633, 0.27327424],\n",
       "       [0.10530299, 0.6237374 , 0.27095962],\n",
       "       [0.10780242, 0.629061  , 0.2631366 ],\n",
       "       [0.10856595, 0.6313884 , 0.26004562],\n",
       "       [0.11088797, 0.632512  , 0.25660005],\n",
       "       [0.10612192, 0.627465  , 0.26641306],\n",
       "       [0.10633817, 0.6245721 , 0.2690897 ],\n",
       "       [0.10408014, 0.62189937, 0.2740205 ],\n",
       "       [0.10975557, 0.6303954 , 0.25984904],\n",
       "       [0.10527136, 0.6223993 , 0.27232933],\n",
       "       [0.0973866 , 0.612051  , 0.29056242],\n",
       "       [0.10546923, 0.6244746 , 0.27005628],\n",
       "       [0.10348749, 0.62382406, 0.27268848],\n",
       "       [0.12218112, 0.64316213, 0.23465675],\n",
       "       [0.09862775, 0.61514467, 0.28622758],\n",
       "       [0.11198839, 0.62878865, 0.25922295],\n",
       "       [0.09911691, 0.61526674, 0.2856164 ],\n",
       "       [0.10077436, 0.6179123 , 0.28131336],\n",
       "       [0.11420289, 0.6331205 , 0.2526766 ],\n",
       "       [0.10761593, 0.6290854 , 0.26329866],\n",
       "       [0.11348945, 0.63590306, 0.25060752],\n",
       "       [0.10585731, 0.6253154 , 0.26882732],\n",
       "       [0.10357138, 0.6248934 , 0.27153522],\n",
       "       [0.10674223, 0.6262896 , 0.26696816],\n",
       "       [0.10075103, 0.616718  , 0.282531  ],\n",
       "       [0.10811458, 0.6303826 , 0.26150286],\n",
       "       [0.10854433, 0.6291952 , 0.26226044],\n",
       "       [0.09944633, 0.6167635 , 0.28379017],\n",
       "       [0.10247235, 0.62254566, 0.27498198],\n",
       "       [0.09369121, 0.6071446 , 0.29916415],\n",
       "       [0.10353672, 0.62382936, 0.27263388],\n",
       "       [0.10910121, 0.6320176 , 0.25888115],\n",
       "       [0.10029783, 0.6173222 , 0.28237998],\n",
       "       [0.11208332, 0.63369083, 0.25422585],\n",
       "       [0.11175156, 0.63260555, 0.2556428 ],\n",
       "       [0.10766714, 0.6305359 , 0.26179698],\n",
       "       [0.11343118, 0.63405526, 0.2525136 ],\n",
       "       [0.10158861, 0.6241431 , 0.27426824],\n",
       "       [0.10516419, 0.62847143, 0.26636437],\n",
       "       [0.10129858, 0.6186529 , 0.2800485 ],\n",
       "       [0.10208923, 0.6233954 , 0.27451533],\n",
       "       [0.10014465, 0.62084705, 0.27900827],\n",
       "       [0.10852978, 0.63057256, 0.26089764],\n",
       "       [0.11181778, 0.6286879 , 0.2594943 ],\n",
       "       [0.10247253, 0.62145656, 0.27607098],\n",
       "       [0.1011696 , 0.62318766, 0.27564272],\n",
       "       [0.10326684, 0.620186  , 0.27654716],\n",
       "       [0.10838865, 0.62838405, 0.26322725],\n",
       "       [0.10249101, 0.62181205, 0.2756969 ],\n",
       "       [0.10434235, 0.62330157, 0.27235606],\n",
       "       [0.10050149, 0.619463  , 0.28003547],\n",
       "       [0.10960684, 0.63074726, 0.25964594],\n",
       "       [0.10418814, 0.6233908 , 0.27242106],\n",
       "       [0.1161995 , 0.6373285 , 0.24647194],\n",
       "       [0.10758135, 0.62890744, 0.26351112],\n",
       "       [0.11278037, 0.63092506, 0.25629455],\n",
       "       [0.10849014, 0.63105744, 0.26045242],\n",
       "       [0.11378618, 0.6343773 , 0.25183654],\n",
       "       [0.09969263, 0.6160369 , 0.28427047],\n",
       "       [0.102053  , 0.61926377, 0.27868322],\n",
       "       [0.10558468, 0.62874424, 0.26567107],\n",
       "       [0.10148537, 0.61983716, 0.27867743],\n",
       "       [0.10880215, 0.6314641 , 0.25973374],\n",
       "       [0.10759504, 0.62931055, 0.26309446],\n",
       "       [0.10843338, 0.6304301 , 0.26113656],\n",
       "       [0.09976774, 0.61941963, 0.28081265],\n",
       "       [0.09725549, 0.616634  , 0.28611043],\n",
       "       [0.11144371, 0.6312215 , 0.25733483],\n",
       "       [0.12350991, 0.6410733 , 0.2354168 ],\n",
       "       [0.10036308, 0.61844784, 0.28118908],\n",
       "       [0.10760154, 0.6280134 , 0.26438507],\n",
       "       [0.10322877, 0.62262124, 0.27414998],\n",
       "       [0.10526754, 0.6235414 , 0.27119106],\n",
       "       [0.10223716, 0.6237015 , 0.27406132],\n",
       "       [0.10957083, 0.6316465 , 0.2587827 ],\n",
       "       [0.10900102, 0.6282101 , 0.2627888 ],\n",
       "       [0.11192343, 0.635969  , 0.2521076 ],\n",
       "       [0.09899412, 0.6164877 , 0.28451824],\n",
       "       [0.11336803, 0.633101  , 0.25353098],\n",
       "       [0.10083774, 0.61735916, 0.2818031 ]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 155, 155, 95, 1)] 0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv3D)               (None, 151, 151, 91, 32)  4032      \n",
      "_________________________________________________________________\n",
      "act1 (Activation)            (None, 151, 151, 91, 32)  0         \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling3D)         (None, 75, 75, 45, 32)    0         \n",
      "_________________________________________________________________\n",
      "class_conv (Conv3D)          (None, 75, 75, 45, 3)     99        \n",
      "_________________________________________________________________\n",
      "class_score (Activation)     (None, 75, 75, 45, 3)     0         \n",
      "_________________________________________________________________\n",
      "flatten_27 (Flatten)         (None, 759375)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 759375)            0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 100)               75937600  \n",
      "_________________________________________________________________\n",
      "batch_normalization_108 (Bat (None, 100)               300       \n",
      "_________________________________________________________________\n",
      "actD1 (Activation)           (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "batch_normalization_109 (Bat (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 75,942,343\n",
      "Trainable params: 75,942,137\n",
      "Non-trainable params: 206\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "branch_input = Input(shape= (155,155,95,1))\n",
    "model_temp = bm.build_separate_model(branch_input)\n",
    "val_data = X_test\n",
    "val_labels = Y_test\n",
    "#val_labels_C = Y_test_C\n",
    "#model_temp = multi_gpu_model(model_temp, gpus=2)\n",
    "opt = keras.optimizers.Adam(lr=2e-4)\n",
    "model_temp.compile(optimizer=opt, loss='categorical_crossentropy', metrics=[tf.keras.metrics.AUC(),'accuracy'])\n",
    "\n",
    "v = 2207\n",
    "model_weights_file = 'img_classifierW_weights_GM_%s.h5' %v\n",
    "epoch_weights_file = 'img_classifierW_weights_GM_%s_{epoch:02d}.hdf5' %v\n",
    "model_file = 'img_classifierW_model_GM%s.h5' %v\n",
    "history_file = 'img_classifierW_history_GM_%s.json' %v\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(epoch_weights_file, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=early_stopping_patience, verbose=1, mode='auto')\n",
    "callbacks_list = [checkpoint, early_stopping]\n",
    "#datagen = ImageDataGenerator(featurewise_center=False, samplewise_center=False, featurewise_std_normalization=False,samplewise_std_normalization=False,zca_whitening=False,rotation_range=15,zoom_range=0.1,width_shift_range=0.1,height_shift_range=0.1,horizontal_flip=False,vertical_flip=False)\n",
    "\n",
    "model_temp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"3d_image_GM_classification.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test=model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3135446 , 0.48260033, 0.20385513],\n",
       "       [0.09735964, 0.74092096, 0.16171935],\n",
       "       [0.26510975, 0.5702893 , 0.16460097],\n",
       "       [0.16024402, 0.69566196, 0.14409405],\n",
       "       [0.06286152, 0.81575   , 0.12138845],\n",
       "       [0.06915223, 0.64327717, 0.28757057],\n",
       "       [0.3204738 , 0.5140704 , 0.16545586],\n",
       "       [0.05898845, 0.6862453 , 0.25476626],\n",
       "       [0.3627639 , 0.4892984 , 0.14793776],\n",
       "       [0.07947076, 0.49687186, 0.4236573 ],\n",
       "       [0.22751333, 0.5600592 , 0.21242748],\n",
       "       [0.09957021, 0.51678145, 0.38364837],\n",
       "       [0.29326108, 0.6549489 , 0.05178995],\n",
       "       [0.0798648 , 0.5989184 , 0.32121682],\n",
       "       [0.20317046, 0.6112332 , 0.18559638],\n",
       "       [0.01086935, 0.45530254, 0.533828  ],\n",
       "       [0.20265634, 0.65257686, 0.14476681],\n",
       "       [0.37942162, 0.47323805, 0.14734033],\n",
       "       [0.18708092, 0.64446324, 0.16845588],\n",
       "       [0.6146676 , 0.33658728, 0.04874525],\n",
       "       [0.22530362, 0.50662786, 0.2680685 ],\n",
       "       [0.41861063, 0.4477514 , 0.13363798],\n",
       "       [0.17755759, 0.47317153, 0.34927094],\n",
       "       [0.12066185, 0.58683145, 0.29250664],\n",
       "       [0.20908625, 0.4574604 , 0.3334533 ],\n",
       "       [0.04881467, 0.7150562 , 0.23612912],\n",
       "       [0.17750861, 0.6520818 , 0.17040959],\n",
       "       [0.18810146, 0.5788498 , 0.23304883],\n",
       "       [0.01395537, 0.8263824 , 0.15966219],\n",
       "       [0.15006892, 0.619303  , 0.230628  ],\n",
       "       [0.2594683 , 0.43365955, 0.30687216],\n",
       "       [0.14098687, 0.7981311 , 0.06088201],\n",
       "       [0.44864473, 0.44955042, 0.10180488],\n",
       "       [0.10299253, 0.47453567, 0.42247185],\n",
       "       [0.3845628 , 0.50144887, 0.1139883 ],\n",
       "       [0.08878932, 0.6528315 , 0.25837916],\n",
       "       [0.11702047, 0.76780176, 0.1151778 ],\n",
       "       [0.18726933, 0.5622792 , 0.2504515 ],\n",
       "       [0.43261075, 0.43440166, 0.1329876 ],\n",
       "       [0.20179145, 0.58652174, 0.2116868 ],\n",
       "       [0.12672786, 0.6713864 , 0.20188576],\n",
       "       [0.36257398, 0.5245564 , 0.11286967],\n",
       "       [0.138905  , 0.65022624, 0.21086879],\n",
       "       [0.22416331, 0.64879483, 0.1270418 ],\n",
       "       [0.28576967, 0.6149634 , 0.09926683],\n",
       "       [0.18147215, 0.7195813 , 0.09894658],\n",
       "       [0.11514018, 0.61972404, 0.26513582],\n",
       "       [0.38713086, 0.46040708, 0.15246207],\n",
       "       [0.17294405, 0.6514873 , 0.17556866],\n",
       "       [0.15746722, 0.6101209 , 0.23241194],\n",
       "       [0.17875431, 0.71387833, 0.10736737],\n",
       "       [0.05576231, 0.58748484, 0.3567528 ],\n",
       "       [0.42763892, 0.4953162 , 0.07704484],\n",
       "       [0.32144797, 0.572229  , 0.10632297],\n",
       "       [0.07750562, 0.5280094 , 0.39448494],\n",
       "       [0.00600466, 0.7057403 , 0.28825504],\n",
       "       [0.15460868, 0.7031328 , 0.14225854],\n",
       "       [0.12375553, 0.6941565 , 0.18208794],\n",
       "       [0.21271788, 0.5759477 , 0.21133442],\n",
       "       [0.1993879 , 0.5269333 , 0.2736788 ],\n",
       "       [0.2575938 , 0.5422255 , 0.20018075],\n",
       "       [0.3933673 , 0.5229844 , 0.08364826],\n",
       "       [0.13890854, 0.45205367, 0.40903777],\n",
       "       [0.26892248, 0.5355314 , 0.19554617],\n",
       "       [0.2764584 , 0.5590624 , 0.16447917],\n",
       "       [0.02119527, 0.7665451 , 0.2122596 ],\n",
       "       [0.30093068, 0.4836826 , 0.21538675],\n",
       "       [0.29646873, 0.6173645 , 0.08616669],\n",
       "       [0.22185606, 0.7194823 , 0.05866168],\n",
       "       [0.03555932, 0.46621794, 0.4982228 ],\n",
       "       [0.00951767, 0.53254443, 0.4579379 ],\n",
       "       [0.24611086, 0.5704406 , 0.18344857],\n",
       "       [0.55000824, 0.41897127, 0.03102051],\n",
       "       [0.43080834, 0.45088494, 0.11830678],\n",
       "       [0.07745138, 0.47940207, 0.4431465 ],\n",
       "       [0.2209027 , 0.53597146, 0.2431258 ],\n",
       "       [0.06369559, 0.7175686 , 0.21873581],\n",
       "       [0.19364163, 0.6009614 , 0.20539697],\n",
       "       [0.02317248, 0.62046903, 0.35635847],\n",
       "       [0.12624046, 0.56020755, 0.31355202],\n",
       "       [0.3146109 , 0.5354369 , 0.1499522 ],\n",
       "       [0.3820258 , 0.49184725, 0.12612705]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_predicted=np_utils.to_categorical(np.argmax(features_test, axis=1),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2., 78.,  2.], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Y_predicted,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19., 48., 15.], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Y_test,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47584498144199633"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(Y_test,Y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4634146341463415"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.argmax(Y_test,axis=1)-np.argmax(features_test, axis=1))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5746268656716418"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(np.argmax(Y_validation, axis=1),np.argmax(features_test, axis=1), pos_label=2)\n",
    "metrics.auc(fpr, tpr)\n",
    "#metrics.auc(np.argmax(Y_test, axis=1),np.argmax(features_test, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=0).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y must have at least two dimensions for multi-output regression but has only one.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-cfa1301c6893>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultioutput\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiOutputClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_multilabel_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiOutputClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# get a list of n_output containing probability arrays of shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# (n_samples, n_classes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \"\"\"\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mfit_params_validated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m    173\u001b[0m             delayed(_fit_estimator)(\n\u001b[1;32m    174\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36m_fit_estimator\u001b[0;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \"\"\"\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             raise ValueError(\"y must have at least two dimensions for \"\n\u001b[0m\u001b[1;32m    163\u001b[0m                              \"multi-output regression but has only one.\")\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y must have at least two dimensions for multi-output regression but has only one."
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "X, y = make_multilabel_classification(random_state=0)\n",
    "clf = MultiOutputClassifier(clf).fit(X, y)\n",
    "# get a list of n_output containing probability arrays of shape\n",
    "# (n_samples, n_classes)\n",
    "y_pred = clf.predict_proba(X)\n",
    "# extract the positive columns for each output\n",
    "y_pred = np.transpose([pred[:, 1] for pred in y_pred])\n",
    "\n",
    "#roc_auc_score(y, y_pred, average=None)\n",
    "#array([0.82..., 0.86..., 0.94..., 0.85... , 0.94...])\n",
    "#from sklearn.linear_model import RidgeClassifierCV\n",
    "#clf = RidgeClassifierCV().fit(X, y)\n",
    "#roc_auc_score(y, clf.decision_function(X), average=None)\n",
    "#array([0.81..., 0.84... , 0.93..., 0.87..., 0.94...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "X, y = make_multilabel_classification(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(735, 100)\n",
      "(82, 100)\n",
      "Explained variation per principal component: [0.2835941  0.1404652  0.12456509 0.05682736 0.03853712 0.02395179\n",
      " 0.01914842 0.01801331 0.01606208 0.01400473]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7feafc221eb0>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_temp.load_weights(\"img_classifierW_weights_77_12.hdf5\")\n",
    "neuron_model=Model(inputs=branch_input,outputs=model_temp.layers[-4].output)\n",
    "features = neuron_model.predict(X_train)\n",
    "features_test=neuron_model.predict(X_test)\n",
    "print(features.shape)\n",
    "print(features_test.shape)\n",
    "feature_extrc=np.concatenate((features,features_test))\n",
    "feature_extrc.shape\n",
    "feature_extrc=pd.concat([pd.DataFrame(feature_extrc),pd.DataFrame(labels)],axis=1)\n",
    "pd.DataFrame(feature_extrc).to_csv(\"/home/dipnilc/Dipnil/features_WI_GM.csv\", header=None, sep=',',index=None)\n",
    "df_ADNI = feature_extrc\n",
    "#df_ADNI['label'] = labels\n",
    "df_ADNI.head()\n",
    "from sklearn.decomposition import PCA\n",
    "pca_ADNI = PCA(n_components=10)\n",
    "#principalComponents_ADNI = pca_ADNI.fit_transform(df_ADNI[feat_cols].values)\n",
    "principalComponents_ADNI = pca_ADNI.fit_transform(df_ADNI.iloc[:,:-1])\n",
    "np.shape(principalComponents_ADNI)\n",
    "pd.DataFrame(principalComponents_ADNI).to_csv(\"/home/dipnilc/Dipnil/features_WI_GM_PCA.csv\", header=None, sep=',',index=None)\n",
    "print('Explained variation per principal component: {}'.format(pca_ADNI.explained_variance_ratio_))\n",
    "variance = pca_ADNI.explained_variance_ratio_ #calculate variance ratios\n",
    "\n",
    "var=np.cumsum(np.round(pca_ADNI.explained_variance_ratio_, decimals=3)*100)\n",
    "var #cumulative sum of variance explained with [n] features\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ylabel('% Variance Explained')\n",
    "plt.xlabel('# of Features')\n",
    "plt.title('PCA Analysis')\n",
    "plt.ylim(9,100.5)\n",
    "plt.style.context('seaborn-whitegrid')\n",
    "\n",
    "\n",
    "plt.plot(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_temp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6551c2d56902>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model_temp' is not defined"
     ]
    }
   ],
   "source": [
    "m = model_temp.fit(X_train, Y_train,batch_size=4,epochs=80,verbose=1, shuffle=True, validation_data=(val_data, val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-fb60cc135014>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m'Saved model history to disk'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_model_and_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#print(save_model_history(m))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#del model_temp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-fb60cc135014>\u001b[0m in \u001b[0;36msave_model_and_weights\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_model_and_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_weights_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_model_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_file' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def save_model_and_weights(model):\n",
    "        model.save(model_file)\n",
    "        model.save_weights(model_weights_file)\n",
    "\n",
    "def save_model_history(m):\n",
    "    with open(history_file, 'wb') as history_json_file:\n",
    "        json.dump(m.history, history_json_file)\n",
    "\n",
    "    return 'Saved model history to disk'\n",
    "print(save_model_and_weights(model_temp))\n",
    "#print(save_model_history(m))\n",
    "#del model_temp\n",
    "#del m\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model_temp, to_file='GM_model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "transfer_model=Sequential()\n",
    "transfer_model.add(VGG16(include_top=False,weights='imagenet',pooling='avg'))\n",
    "transfer_model.add(Dense(3,activation='softmax'))\n",
    "transfer_model.layers[0].trainable=False\n",
    "transfer_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=[tf.keras.metrics.AUC(),'accuracy'])\n",
    "transfer_model.summary()\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
